{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"VirtualDocs \u2013 API and Generative AI Testing for SaaS Platforms","text":"<p>VirtualDocs is a documentation system and execution model designed for modern engineering teams testing mission-critical APIs and large-scale Generative AI interfaces.</p> <p>This documentation provides a reference-level, no-nonsense framework for defining, validating, and managing tests across microservices, AI endpoints, and multi-environment deployments. Whether you're testing REST APIs, validating JSON responses, benchmarking token outputs from language models, or integrating with CI/CD pipelines \u2014 VirtualDocs is designed to scale.</p>"},{"location":"#purpose","title":"Purpose","text":"<p>Modern software systems increasingly rely on deeply interconnected services and AI systems. The complexity of these integrations demands not just correctness, but resilience, reproducibility, and observability across all surfaces.</p> <p>VirtualDocs is focused on:</p> <ul> <li>Enabling testable, predictable behavior in both deterministic APIs and probabilistic AI systems</li> <li>Supporting regulated environments where auditability and traceability are required (healthcare, finance, govtech)</li> <li>Providing clean and developer-centric tooling with real-world flexibility</li> </ul>"},{"location":"#audience","title":"Audience","text":"<p>This documentation is intended for:</p> <ul> <li>Backend developers maintaining SaaS microservices or domain APIs</li> <li>ML engineers deploying or fine-tuning GenAI models behind public endpoints</li> <li>QA and DevOps engineers building automated test suites for infrastructure validation</li> <li>Technical leads responsible for compliance, stability, and monitoring of live services</li> </ul>"},{"location":"#core-capabilities","title":"Core Capabilities","text":""},{"location":"#1-api-test-design-yaml-sdk","title":"1. API Test Design (YAML / SDK)","text":"<ul> <li>Human-readable YAML test definitions</li> <li>Request-response validation with schema support</li> <li>Header and body assertions</li> <li>Status code verification</li> <li>Custom test naming, grouping, and tagging</li> </ul>"},{"location":"#2-genai-prompt-testing-planned-sdk-yaml-spec","title":"2. GenAI Prompt Testing (Planned SDK / YAML Spec)","text":"<ul> <li>Prompt and completion structure definitions</li> <li>Token budget constraints</li> <li>Latency benchmarking</li> <li>Output matching (regex, semantic match, exact string)</li> <li>Hallucination detection workflows (planned)</li> <li>System prompt conditioning tests</li> </ul>"},{"location":"#3-execution-environment","title":"3. Execution Environment","text":"<ul> <li>Environment variable support (<code>.env</code>, CI secrets)</li> <li>Profile switching (staging, production, preview)</li> <li>Support for test bundles and batch runs</li> <li>CLI-based execution (planned)</li> <li>Python SDK-based test automation</li> </ul>"},{"location":"#4-authentication","title":"4. Authentication","text":"<ul> <li>Bearer Token</li> <li>OAuth2 with token injection</li> <li>Dynamic token fetching via pre-request hooks</li> <li>Header templates per environment</li> </ul>"},{"location":"#5-output-reporting-planned","title":"5. Output &amp; Reporting (Planned)","text":"<ul> <li>Terminal output with summary tables</li> <li>JSON output for CI consumption</li> <li>Future: HTML or markdown reports with pass/fail visualization</li> <li>CI pipeline integration (GitHub Actions, CircleCI, GitLab, Jenkins)</li> </ul>"},{"location":"#file-structure-example","title":"File Structure Example","text":""}]}